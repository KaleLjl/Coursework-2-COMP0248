# Progress Tracking: Table Detection from 3D Point Clouds

## Overall Project Status

```mermaid
pie title Project Implementation Status
    "Pipeline A" : 60
    "Pipeline B" : 0
    "Pipeline C" : 0
    "RealSense Data Collection" : 0
    "Documentation & Report" : 15
```

The project is in its early stages with focus primarily on Pipeline A implementation. Pipelines B and C have not yet been started. Documentation and setup are partially complete.

## Pipeline A: Depth to Point Cloud Classification

### What Works

- âœ… Basic project structure and organization
- âœ… Configuration system for managing parameters
- âœ… Point cloud generation from depth maps
- âœ… Dataset loading from MIT sequences
- âœ… Point cloud preprocessing and normalization
- âœ… Neural network architectures (DGCNN, PointNet)
- âœ… Basic training and evaluation scripts
- âœ… Visualization utilities for point clouds
- âœ… Initial model training implementation
- âœ… TensorBoard integration for tracking metrics
- âœ… Metric computation and visualization

### In Progress

- ğŸ”„ Major dataset split restructuring
  - âœ… Decided to use MIT sequences for training, Harvard sequences for validation
  - ğŸ”„ Implementing the new dataset loading logic
  - ğŸ”„ Adapting training parameters to ensure generalization to Harvard validation set
- ğŸ”„ Addressing model overfitting issues
  - âœ… Identified root causes: model capacity vs. dataset size and train/val split methodology
  - âœ… Updated configuration parameters with stronger regularization and augmentation
  - ğŸ”„ Implementing feature-level dropout and advanced regularization
- ğŸ”„ Data augmentation enhancement for point clouds
  - âœ… Increased rotation range, jitter, and scale variation
  - ğŸ”„ Implementing point dropout and random subsampling
- ğŸ”„ Balancing model complexity with dataset size
  - ğŸ”„ Testing reduced embedding dimensions
  - ğŸ”„ Comparing DGCNN and PointNet generalization
- ğŸ”„ Hyperparameter optimization

### Not Started

- âŒ Thorough evaluation on new validation set (Harvard sequences)
- âŒ Performance analysis and comparison with baseline
- âŒ Integration of optimal model into final pipeline

### Known Issues

- ğŸ **Current Focus**: Previously, training metrics (accuracy, F1-score) increased while validation metrics stagnated
  - ğŸ” Root cause identified: Model capacity too high for dataset size + non-optimal validation split
  - ğŸ› ï¸ Solution in progress: Enhanced regularization and complete restructuring of dataset split
- ğŸ New dataset configuration needs to ensure model generalizes well from MIT training to Harvard validation sequences
- ğŸ **Label Format Inconsistency**: The harvard_tea_2 dataset only has the "depth" label format while other datasets have the "depthTSDF" label format
  - ğŸ› ï¸ Requires special handling in the data loading pipeline
  - ğŸ› ï¸ May affect validation results if not properly processed
- ğŸ Handling of invalid depth values needs improvement
- ğŸ Point cloud sampling strategy may need optimization
- ğŸ Need to address missing table labels in some frames
- ğŸ Potential class imbalance in new training/validation configuration

## Pipeline B: RGB to Depth to Classification

### Status: Not Started

Planned components:
- Monocular depth estimation model
- Depth classification model
- Training and evaluation framework

## Pipeline C: Depth to Point Cloud Segmentation

### Status: Not Started

Planned components:
- Point cloud processing for segmentation
- Segmentation model implementation
- Evaluation and visualization tools

## RealSense Data Collection

### Status: Not Started

Planned activities:
- Setup of RealSense camera
- Planning of capture environments
- Data collection sessions
- Data processing and organization

## Additional Tasks

### Documentation

- âœ… README with project overview
- âœ… Setup instructions
- âœ… Memory bank initialization
- ğŸ”„ Memory bank updates for current challenges
- âŒ Report draft

### Experiment Tracking

- âœ… Setting up experiment tracking with TensorBoard
- âœ… Initial metric visualization
- ğŸ”„ Enhanced monitoring for overfitting
- âŒ Creating additional visualization scripts

## Key Decision Evolution

### Dataset Split Strategy

Initial approach: Use MIT sequences for training with random 80/20 split for validation, and Harvard sequences for testing.

Previous issue: Validation data was too similar to training data, not providing a strong generalization signal.

Current strategy:
- Using MIT sequences (~290 frames) for training (larger dataset)
- Using Harvard sequences (~98 frames) for validation (smaller dataset)
- Test dataset to remain empty for now
- This approach provides a much stronger test of generalization
- Uses the larger dataset for training while ensuring validation tests generalization to a different data distribution

### Model Architecture

Initial decision: Use DGCNN as primary architecture due to its strong performance on point cloud tasks.

Previous evaluation: DGCNN shows strong capacity to learn training data but may be prone to overfitting.

Current direction:
- Confirmed that DGCNN's high capacity is contributing to overfitting with our limited dataset
- Implementing stronger regularization (dropout 0.5 â†’ 0.7, weight decay 1e-4 â†’ 5e-4)
- Adding feature-level dropout (0.2) to prevent co-adaptation
- Planning to test reduced embedding dimensions (1024 â†’ 512)
- Will compare against PointNet for generalization performance

### Regularization Strategy

Initial approach: Standard dropout (0.5) and normalization techniques (GroupNorm, LayerNorm).

Previous direction: Exploring more aggressive regularization.

Current implementation:
- Increased dropout to 0.7 in the configuration
- Added feature-level dropout concept (0.2)
- Increased weight decay to 5e-4
- Added gradient clipping parameter (1.0)
- Enhanced data augmentation (wider rotation ranges, increased jitter, point dropout)

### Training Strategy

Initial approach: Standard training with early stopping based on validation F1-score.

Previous direction: Enhanced monitoring of training/validation divergence.

Current implementation:
- Fundamentally changed the dataset split strategy for better generalization measurement
- Added gradient clipping to prevent extreme weight updates
- Added mixup parameter for implementation
- Planning to implement train/validation divergence metric for early warning
- Will need to establish new baselines with the new dataset configuration

## Milestones and Timeline

| Milestone | Target Date | Status |
|-----------|-------------|--------|
| Pipeline A implementation | TBD | 65% Complete |
| Address overfitting in Pipeline A | TBD | In Progress (~40% Complete) |
| Pipeline B implementation | TBD | Not Started |
| Pipeline C implementation | TBD | Not Started |
| RealSense data collection | TBD | Not Started |
| Report draft | TBD | Not Started |
| Final submission | TBD | Not Started |
